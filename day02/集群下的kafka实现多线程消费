上一篇文章讲述了如何部署kafka集群，而这篇文章则来探讨一下如何使用多线程消费，提高消费能力，保障数据的时效性。而实现多线程消费其实很简单，只需要三步即可：
一：kafka集群配置

多线程消费，说白了就是多区消费，kafka可以给topic设置多个partition，从而实现生产的时候提交到不同的分区，以减少统一区块的压力。而消费则是从不同的分区里拿数据进行消费。

1.首先修改server.properties里：
num.partitions=3
这里等于3是因为本人的集群是用了三台机子，也就是3个broker，所以设置成3，具体数值可以根据集群情况设置。
2.创建topic：
bin/kafka-topics.sh –create –zookeeper 192.168.0.1:2181,192.168.0.2:2181,192.168.0.3:2181 –replication-factor 3 –partitions 3 –topic test
这里的3对应上面的配置里的num.partitions=3
3.查看topic信息：
./kafka-topics.sh –zookeeper 192.168.0.1:2181,192.168.0.2:2181,192.168.0.3:2181 –topic test–describe
会有如下显示表示创建成功：
Topic:test PartitionCount:3 ReplicationFactor:3 Configs:
Topic: test Partition: 0 Leader: 2 Replicas: 2,0,1 Isr: 0,1,2
Topic: test Partition: 1 Leader: 0 Replicas: 0,1,2 Isr: 0,1,2
Topic: test Partition: 2 Leader: 1 Replicas: 1,2,0 Isr: 0,1,2
二：生产者随机分区提交数据

这也是一个比较关键步骤，只有随机提交到不同的分区才能实现多分区消费；
这里借用了一片代码，自定义随机分区：
public class MyPartition implements Partitioner{
     private static Logger LOG = LoggerFactory.getLogger(MyPartition.class); 
    @Override
    public void configure(Map<String, ?> arg0) {
        // TODO Auto-generated method stub
    }

    @Override
    public void close() {
        // TODO Auto-generated method stub
    }

    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value,
            byte[] valueBytes, Cluster cluster) {
        List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
        int numPartitions = partitions.size();
        int partitionNum = 0;
        try {
            partitionNum = Integer.parseInt((String) key);
        } catch (Exception e) {
            partitionNum = key.hashCode() ;
        }
//        System.out.println("kafkaMessage topic:"+ topic+" |key:"+ key+" |value:"+value);
        return Math.abs(partitionNum  % numPartitions);
    }
}
